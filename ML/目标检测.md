# 目标检测

## 算法分类

**目标检测（Object Detection）**的任务是找出图像中所有感兴趣的目标，确定它们的**类别**和**位置**，是计算机视觉领域的核心问题之一。

目前学术和工业界出现的目标检测算法分成3类：

1. **传统的目标检测算法**：**Cascade + HOG/DPM + Haar/SVM**以及上述方法的改进、优化；
2. **候选区域 + 深度学习分类（Two stage）**：通过提取候选区域，并对相应区域进行以深度学习方法为主的分类的方案：**R-CNN系列**等
3. **基于深度学习的回归方法（One stage）**：**YOLO/SSD/DenseBox** 等

https://github.com/amusi/awesome-object-detection



## 基本组件

**边界框bounding box**





## R-CNN

预先找出图中目标可能出现的位置，即**候选区域（Region Proposal）**，利用图像中的纹理、边缘、颜色等信息，可以保证在选取较少窗口(几千甚至几百）的情况下保持较高的召回率（Recall）。选定候选框Region Proposal的方法，**选择性搜索（Selective Search）**

**具体步骤则如下**

一、训练一个分类模型（比如AlexNet）

二、对该模型做fine-tuning

​	1、将分类数从1000改为21，比如20个物体类别 + 1个背景

​	2、去掉最后一个全连接层

三、特征提取

​	1、提取图像的所有候选框（选择性搜索Selective Search）

​	2、对于每一个区域：修正区域大小以适合CNN的输入，做一次前向运算，将第五个池化层的输出（就是对候选框提取到的特征）存到硬盘

四：训练一个SVM分类器（二分类）来判断这个候选框里物体的类别。

​	  每个类别对应一个SVM，判断是不是属于这个类别，是就是positive，反之nagative。

五：使用回归器精细修正候选框位置：对于每一个类，训练一个线性回归模型去判定这个框是否框得完美。



**存在问题**

R-CNN虽然不再像传统方法那样穷举，但R-CNN流程的第一步中对原始图片通过Selective Search提取的候选框region proposal多达2000个左右，而这2000个候选框每个框都需要进行CNN提特征+SVM分类，计算量很大，导致R-CNN检测速度很慢，一张图都需要47s。

有没有方法提速呢？答案是有的，这2000个region proposal不都是图像的一部分吗，那么我们完全可以对图像提一次卷积层特征，然后只需要将region proposal在原图的位置映射到卷积层特征图上，这样对于一张图像我们只需要提一次卷积层特征，然后将每个region proposal的卷积层特征输入到全连接层做后续操作。

但现在的问题是每个region proposal的尺度不一样，而全连接层输入必须是固定的长度，所以直接这样输入全连接层肯定是不行的。SPP Net恰好可以解决这个问题。



## SPP-Net

**SPP：Spatial Pyramid Pooling（空间金字塔池化）**

当全连接层面对各种尺寸的输入数据时，就需要对输入数据进行**crop**等一系列操作以统一图片的尺寸大小，比如224x224（ImageNet）、32x32(LeNet)、96x96等（crop就是从一个大图扣出网络输入大小的patch，比如227×227），或warp（把一个边界框bounding box的内容resize成227×227

但warp/crop这种预处理，导致的问题要么被拉伸变形、要么物体不全，限制了识别精确度。

那借鉴卷积层可以适应任何尺寸，为何不能在卷积层的最后加入某种结构，使得后面全连接层得到的输入变成固定的呢？

这个结构就是**spatial pyramid pooling layer**



**SPP的特点有两个:**

**1、**在普通的CNN机构中，输入图像的尺寸往往是固定的（比如224*224像素），输出则是一个固定维数的向量。

SPP Net在普通的CNN结构中加入了**ROI池化层（ROI Pooling）**，使得网络的输入图像可以是任意尺寸的，输出则是一个固定维数的向量。

ROI池化层一般跟在卷积层后面，此时网络的输入可以是任意尺度的，在SPP layer中每一个pooling的filter会根据输入调整大小，而SPP的输出则是固定维数的向量，然后给到全连接FC层。

**2、**只对原图提取一次卷积特征

在R-CNN中，每个候选框先resize到统一大小，然后分别作为CNN的输入，这样是很低效的。

而SPP Net根据这个缺点做了优化：只对原图进行一次卷积计算，便得到整张图的**卷积特征feature map**，然后找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层，完成特征提取工作。



**ROI pooling**

（1）根据输入image，将ROI映射到feature map对应位置；

（2）将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）；

（3）对每个sections进行max pooling操作；

例如：一个8x8大小的feature map，一个ROI，输出大小为2x2.

![image-20200109044751910](J:\03_NOTES\ML\目标检测.assets\image-20200109044751910.png)



## Fast RCNN

Fast R-CNN在R-CNN的基础上采纳了SPP Net方法，对R-CNN作了改进，使得性能进一步提高。

与R-CNN框架图对比，主要有两处不同：

一、最后一个卷积层后加了一个**ROI pooling layer**，

二、损失函数使用了**分类加回归多任务损失函数(multi-task loss)**，将边框回归Bounding Box Regression直接加入到CNN网络中训练。



## Faster RCNN

Fast RCNN存在的问题：选择性搜索，找出所有的候选框，这个也非常耗时。

所以，在Faster RCNN中引入**Region Proposal Network(RPN)**替代Selective Search，同时引入**anchor box**应对目标形状的变化。

![image-20200109045125063](J:\03_NOTES\ML\目标检测.assets\image-20200109045125063.png)

**RPN(Region Proposal Network)**

考虑9个可能的候选窗口：三种面积{128,256,512}×三种比例{1:1,1:2,2:1}。这些候选窗口称为**anchors**。

![image-20200109045423205](J:\03_NOTES\ML\目标检测.assets\image-20200109045423205.png)

**RPN步骤：**

得到9个anchor，我们给每个anchor分配一个二进制的标签（前景:1,背景:0）。

我们分配正标签给两类anchor：

**1）**与某个**ground truth（GT）**包围盒有最高的IoU重叠的anchor（也许不到0.7），

**2）**与任意GT有大于0.7的IoU交叠的anchor。

注意到一个GT包围盒可能分配正标签给多个anchor。我们分配负标签给与所有GT包围盒的IoU比率都低于0.3的anchor。非正非负的anchor对训练目标没有任何作用，由此输出维度为2x9=18，一共18维。

假设在feature map中每个点上有k个anchor（默认k=9），而每个anhcor要分前景和背景，所以每个点转化为cls=2k 分类scores；而每个anchor都有[x, y, w, h]对应4个偏移量，所以reg=4k 回归坐标(coordinates)

**3）**边框回归：已经计算出前景anchors，使用bounding box regression得到预设anchor-box到ground-truth-box之间的变换参数，即平移（dx和dy）和伸缩参数（dw和dh），由此得到初步确定proposal。

对于窗口一般使用四维向量(x, y, w, h)表示，分别表示窗口的中心点坐标和宽高。我们的目标是寻找一种关系，使得输入原始的anchor A经过映射得到一个跟真实窗口G更接近的预测窗口G'，

**即：给定anchor A=(Ax, Ay, Aw, Ah)，寻找映射f，使得f(Ax, Ay, Aw, Ah)=(G'x, G'y, G'w, G'h)，使(G'x, G'y, G'w, G'h)≈(Gx, Gy, Gw, Gh)。**

**4）**将预测的proposal将anchors映射回原图，判断预测的proposal是否大范围超过边界，剔除严重超出边界的。

**5）**按照分类score进行从大到小排序，提取前2000个预proposal，对这个2000个进行**NMS(非极大值抑制)**，将得到的再次进行排序，输出300个proposal。



## SSD
***

![image-20200109222733184](J:\03_NOTES\ML\目标检测.assets\image-20200109222733184.png)

### DSSD
***

![image-20200110005948673](J:\03_NOTES\ML\目标检测.assets\image-20200110005948673.png)

### DSOD
***

![image-20200110012304750](J:\03_NOTES\ML\目标检测.assets\image-20200110012304750.png)



### FSSD
***

借鉴FPN的思想，重构一组特征图金字塔，使算法精度明显提升，速度没有下降太多。

![image-20200110013656284](J:\03_NOTES\ML\目标检测.assets\image-20200110013656284.png)



### RSSD

***



![image-20200110015218210](J:\03_NOTES\ML\目标检测.assets\image-20200110015218210.png)



## RetinaNet

***





## Yolo系列

***





# 文本检测















